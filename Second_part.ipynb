{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1884bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab138f",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8628473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"kaggle_data/train_data.pkl\")\n",
    "test_data = pd.read_pickle(\"kaggle_data/test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f51b2",
   "metadata": {},
   "source": [
    "# data transform and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fe9a9",
   "metadata": {},
   "source": [
    "## TFIDF with n samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2406f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d1fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_train_data = train_data.groupby(\"emotion\").sample(n=5000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f3bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anticipation    5000\n",
       "anger           5000\n",
       "fear            5000\n",
       "disgust         5000\n",
       "joy             5000\n",
       "surprise        5000\n",
       "sadness         5000\n",
       "trust           5000\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_train_data.sample(frac=1)\n",
    "TFIDF_train_data['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce5d2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsnl/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000,\n",
       "                tokenizer=<function word_tokenize at 0x7fcfee9399d0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF_vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
    "TFIDF_vectorizer = TfidfVectorizer(max_features=1000, tokenizer=nltk.word_tokenize)\n",
    "TFIDF_vectorizer.fit(TFIDF_train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a339022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif os.path.isfile(\\'kaggle_data/TFIDF_X_train.npz\\'):\\n    X_train = sparse.load_npz(\\'kaggle_data/TFIDF_X_train.npz\\')\\nelse:\\n    X_train = TFIDF_vectorizer.transform(train_data[\\'text\\'])\\n    sparse.save_npz(\"kaggle_data/TFIDF_X_train.npz\", X_train)\\n    \\nY_train = train_data[\\'emotion\\']\\n \\nif os.path.isfile(\\'kaggle_data/TFIDF_X_test.npz\\'):\\n    X_test = sparse.load_npz(\\'kaggle_data/TFIDF_X_test.npz\\')\\nelse:\\n    X_test = TFIDF_vectorizer.transform(test_data[\\'text\\'])\\n    sparse.save_npz(\"kaggle_data/TFIDF_X_test.npz\", X_test)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_tokenized = TFIDF_vectorizer.transform(TFIDF_train_data['text'])\n",
    "trained_answer = TFIDF_train_data['emotion']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(trained_tokenized, trained_answer, test_size=0.25, random_state=42)\n",
    "\n",
    "target = TFIDF_vectorizer.transform(test_data['text'])\n",
    "\n",
    "'''\n",
    "if os.path.isfile('kaggle_data/TFIDF_X_train.npz'):\n",
    "    X_train = sparse.load_npz('kaggle_data/TFIDF_X_train.npz')\n",
    "else:\n",
    "    X_train = TFIDF_vectorizer.transform(train_data['text'])\n",
    "    sparse.save_npz(\"kaggle_data/TFIDF_X_train.npz\", X_train)\n",
    "    \n",
    "Y_train = train_data['emotion']\n",
    " \n",
    "if os.path.isfile('kaggle_data/TFIDF_X_test.npz'):\n",
    "    X_test = sparse.load_npz('kaggle_data/TFIDF_X_test.npz')\n",
    "else:\n",
    "    X_test = TFIDF_vectorizer.transform(test_data['text'])\n",
    "    sparse.save_npz(\"kaggle_data/TFIDF_X_test.npz\", X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b6937b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1000)\n",
      "(30000,)\n",
      "(10000, 1000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78de4d",
   "metadata": {},
   "source": [
    "### decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47be464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'fear', 'trust', ..., 'surprise', 'fear', 'fear'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "DT_model = DT_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2b1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "acc_train = accuracy_score(y_true=Y_test, y_pred=Y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0833391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  94 168 133 146 152 145 115]\n",
      " [102 395 116  68 188 110 121 174]\n",
      " [178 114 268 129 120 181 154 121]\n",
      " [101 105 111 479 108 101 114  86]\n",
      " [106 143  97 101 363 107 127 186]\n",
      " [128 106 144 122 114 355 150 121]\n",
      " [120 107 164 108 115 126 384 128]\n",
      " [113 158 117  89 201 111 118 350]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_test, y_pred=Y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb625f0b",
   "metadata": {},
   "source": [
    "### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "811b3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dddf9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55b52397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.37\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_true=Y_test, y_pred=Y_test_pred)\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "600664bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[481  94 198 122  82 111 108  81]\n",
      " [ 72 609  95  85 145  68  57 143]\n",
      " [165  95 429 128  78 184 117  69]\n",
      " [ 67 104 108 578  82 100  82  84]\n",
      " [ 84 184  80 114 368  85  77 238]\n",
      " [143  99 236 114  71 387 109  81]\n",
      " [111  98 186 152  93 121 386 105]\n",
      " [ 62 188  85  98 191  72  69 492]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_test, y_pred=Y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83a31b",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "134ab423",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestClassifier(n_estimators=100,n_jobs = -1,random_state =50, min_samples_leaf = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6153fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = forest_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a28b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.37\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_true=Y_test, y_pred=Y_test_pred)\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd1605c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[501  56 198 136 126 100  70  90]\n",
      " [106 530 101  98 170  63  38 168]\n",
      " [215  59 406 117 106 194  74  94]\n",
      " [115  63 112 603 102  75  41  94]\n",
      " [119 113  95 114 478  60  39 212]\n",
      " [175  61 222 113 123 389  59  98]\n",
      " [151  59 216 132 130 120 342 102]\n",
      " [106 140 129  93 205  65  43 476]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_test, y_pred=Y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ebfa3",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e0a5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfbdeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsnl/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LR.fit(X_train, Y_train)\n",
    "Y_test_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceae543a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.39\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy_score(y_true=Y_test, y_pred=Y_test_pred)\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd5d8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[515  90 164 106  89 118 111  84]\n",
      " [ 92 607  75  75 161  61  59 144]\n",
      " [172  78 405 111  84 194 143  78]\n",
      " [ 90  93  95 596  92  86  83  70]\n",
      " [ 95 148  76  92 424  77  90 228]\n",
      " [162  83 201 103 106 386 118  81]\n",
      " [133  78 151 117 114 116 440 103]\n",
      " [ 90 170  83  73 203  69  70 499]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true=Y_test, y_pred=Y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823ffc6",
   "metadata": {},
   "source": [
    "### deep learning model\n",
    "kera taught by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff8f7b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "y_train[0:4]:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (15000, 8) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-fed232cf61e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-fed232cf61e2>\u001b[0m in \u001b[0;36mlabel_encode\u001b[1;34m(le, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlabel_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[0;32m    132\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;31m# transform of empty array is empty array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (15000, 8) instead."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_data['emotion'])\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('y_train[0:4]:\\n', Y_train[0:4])\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "Y_train = label_encode(label_encoder, Y_train)\n",
    "Y_test = label_encode(label_encoder, Y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('Y_train[0:4]:\\n', Y_train[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "340ec89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  1000\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0202e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 1000)]            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               128128    \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " re_lu_11 (ReLU)             (None, 128)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      " softmax_5 (Softmax)         (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,672\n",
      "Trainable params: 145,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, GlobalAvgPool1D\n",
    "from keras.layers import ReLU, Softmax, Dropout\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=128)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=128)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a4b565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<15000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 207342 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d23a9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change to sparse tensor, so it can be model's input\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
    "\n",
    "X_train_enc = convert_sparse_matrix_to_sparse_tensor(X_train)\n",
    "X_test_enc = convert_sparse_matrix_to_sparse_tensor(X_test)\n",
    "target_enc = convert_sparse_matrix_to_sparse_tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b288237",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_5/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_5/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_5/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 3s 5ms/step - loss: 1.6333 - accuracy: 0.4055 - val_loss: 1.5211 - val_accuracy: 0.4466\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.4057 - accuracy: 0.4909 - val_loss: 1.4971 - val_accuracy: 0.4548\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 1.2828 - accuracy: 0.5407 - val_loss: 1.5184 - val_accuracy: 0.4590\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1611 - accuracy: 0.5831 - val_loss: 1.5693 - val_accuracy: 0.4478\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0140 - accuracy: 0.6429 - val_loss: 1.6676 - val_accuracy: 0.4428\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.8398 - accuracy: 0.7140 - val_loss: 1.8228 - val_accuracy: 0.4334\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.6544 - accuracy: 0.7890 - val_loss: 1.9939 - val_accuracy: 0.4148\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4805 - accuracy: 0.8589 - val_loss: 2.2424 - val_accuracy: 0.4092\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3358 - accuracy: 0.9063 - val_loss: 2.5540 - val_accuracy: 0.4076\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2371 - accuracy: 0.9389 - val_loss: 2.8577 - val_accuracy: 0.3920\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1707 - accuracy: 0.9580 - val_loss: 3.1070 - val_accuracy: 0.4070\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1243 - accuracy: 0.9691 - val_loss: 3.3728 - val_accuracy: 0.3964\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 3.6322 - val_accuracy: 0.3880\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0779 - accuracy: 0.9804 - val_loss: 3.8928 - val_accuracy: 0.3998\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0661 - accuracy: 0.9828 - val_loss: 4.0364 - val_accuracy: 0.3900\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0593 - accuracy: 0.9845 - val_loss: 4.2812 - val_accuracy: 0.3998\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0549 - accuracy: 0.9859 - val_loss: 4.3607 - val_accuracy: 0.3936\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0494 - accuracy: 0.9865 - val_loss: 4.5771 - val_accuracy: 0.3810\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0532 - accuracy: 0.9843 - val_loss: 4.7458 - val_accuracy: 0.3882\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0512 - accuracy: 0.9863 - val_loss: 4.8924 - val_accuracy: 0.3886\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 4.9686 - val_accuracy: 0.3756\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9872 - val_loss: 5.1703 - val_accuracy: 0.3930\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 5.2205 - val_accuracy: 0.3780\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 5.2952 - val_accuracy: 0.3920\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9903 - val_loss: 5.4753 - val_accuracy: 0.3804\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 5.4304 - val_accuracy: 0.3790\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 5.4851 - val_accuracy: 0.3932\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 5.5665 - val_accuracy: 0.3904\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 5.6236 - val_accuracy: 0.3814\n",
      "Epoch 30/50\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 0.0332 - accuracy: 0.9895"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-d9098436ad02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# training!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m history = model.fit(X_train_enc, Y_train, \n\u001b[0m\u001b[0;32m     11\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/kaggle_training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train_enc, Y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test_enc, Y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67cdfb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3219/3219 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'anticipation', 'trust',\n",
       "       'anticipation'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "target_result = model.predict(target_enc, batch_size=128)\n",
    "target_result = label_decode(label_encoder, target_result)\n",
    "target_result[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289297d1",
   "metadata": {},
   "source": [
    "# result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c1ec684",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv = pd.DataFrame(columns=['id', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5697f0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hashtags  tweet_id  \\\n",
       "2                             [bibleverse]  0x28b412   \n",
       "4                                       []  0x2de201   \n",
       "9        [materialism, money, possessions]  0x218443   \n",
       "30                    [GodsPlan, GodsWork]  0x2939d5   \n",
       "33                                      []  0x26289a   \n",
       "...                                    ...       ...   \n",
       "1867525                                 []  0x2913b4   \n",
       "1867529                                 []  0x2a980e   \n",
       "1867530    [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                                 []  0x29d0cb   \n",
       "1867532                                 []  0x2a6a4f   \n",
       "\n",
       "                                                      text identification  \n",
       "2        Confident of your obedience, I write to you, k...           test  \n",
       "4        \"Trust is not the same as faith. A friend is s...           test  \n",
       "9        When do you have enough ? When are you satisfi...           test  \n",
       "30       God woke you up, now chase the day #GodsPlan #...           test  \n",
       "33       In these tough times, who do YOU turn to as yo...           test  \n",
       "...                                                    ...            ...  \n",
       "1867525  \"For this is the message that ye heard from th...           test  \n",
       "1867529  \"There is a lad here, which hath five barley l...           test  \n",
       "1867530  When you buy the last 2 tickets remaining for ...           test  \n",
       "1867531  I swear all this hard work gone pay off one da...           test  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...           test  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71e503b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id emotion\n",
       "2        0x28b412     NaN\n",
       "4        0x2de201     NaN\n",
       "9        0x218443     NaN\n",
       "30       0x2939d5     NaN\n",
       "33       0x26289a     NaN\n",
       "...           ...     ...\n",
       "1867525  0x2913b4     NaN\n",
       "1867529  0x2a980e     NaN\n",
       "1867530  0x316b80     NaN\n",
       "1867531  0x29d0cb     NaN\n",
       "1867532  0x2a6a4f     NaN\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv['id'] = test_data['tweet_id']\n",
    "result_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac2f5dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       emotion\n",
       "2        0x28b412  anticipation\n",
       "4        0x2de201  anticipation\n",
       "9        0x218443  anticipation\n",
       "30       0x2939d5         trust\n",
       "33       0x26289a  anticipation\n",
       "...           ...           ...\n",
       "1867525  0x2913b4           joy\n",
       "1867529  0x2a980e       disgust\n",
       "1867530  0x316b80  anticipation\n",
       "1867531  0x29d0cb           joy\n",
       "1867532  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv['emotion'] = target_result\n",
    "result_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f6ee5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv.to_csv(\"kaggle_data/result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0dd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
